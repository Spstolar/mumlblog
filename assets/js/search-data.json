{
  
    
  
    
        "post1": {
            "title": "Make More Interesting Random Music",
            "content": "Make More Interesting Random Music . We saw last time that it is simple to construct a MIDI file with the pretty_midi package. Now to make something a little more musically interesting than alternating between two notes we need to randomly generate notes to play using some basic music theory to make things sound “good.” To do this we will: . choose a scale | find all of the midi notes attached to that scale | randomly draw notes from that collection of midi notes | get a pleasing collection of simple chords to accompany the melody | vary the rhythm of the melody | . Pick a Scale . First we use a couple of nice utilities of pretty_midi, a method which takes an integer and spits out one of the major and minor keys and another method which takes that same integer and returns how many accidentals the key has. Using the key name we can determine whether the key has flat accidentals or sharp accidentals and then by using the fact that “accidentals accumulate” (if a key has a G# then it also has a C#, for example) we can easily identify which notes are in the key. . To say more, we are using the fact that the Major and Minor keys have certain nice patterns. If we start from C and move up in perfect 5ths (C, G, D, A) then those corresponding (major) keys each add an accidental: . C Major: CDEFGAB | G Major: GABCDEF# | D Major: DEF#GABC# | A Major: ABC#DEF#G# | … | . This means we know the exact notes that are made sharp or (flat) if we know if the key is sharp (flat) and how many accidentals there are, we do not even need to know the root: we are being told the same information in a different way. Now, there is actually a more insightful way to do this (how making major scales is normally taught) by using the fact that you start at the root and add notes with the pattern WWHWWWH, but it was fun to think of a different way to get the notes. . We return the key_notes which runs from C to B because this is how the MIDI format is laid out for each octave (… B1 C2 C#2 … A#2 B2 C3 …), but we also save off the notes of the key starting from the root for (optional) printing to the user as scale_notes. . note_names = [n for n in &#39;CDEFGAB&#39;] sharp_accidentals = [n for n in &#39;FCGDAEB&#39;] flat_accidentals = [n for n in &#39;BEADGCF&#39;] def determine_key_notes(key_number): key_name = pretty_midi.key_number_to_key_name(key_number) _, num_accidentals = pretty_midi.key_number_to_mode_accidentals(key_number) root = key_name[0] root_index = note_names.index(root) if key_name[1] == &quot;b&quot;: accidental_mark = &#39;b&#39; accidentals = flat_accidentals[:num_accidentals] else: accidental_mark = &#39;#&#39; accidentals = sharp_accidentals[:num_accidentals] key_notes = list(map(lambda n: n + accidental_mark if n in accidentals else n, note_names)) scale_notes = (key_notes + key_notes)[root_index:root_index + 7] . Find All MIDI Notes Given Key Notes . For this, use the pretty_midi utility that converts note names to MIDI note numbers and apply it to all the note names with all the octave numbers attached. . def get_all_midi_numbers(note_names): midi_numbers = [] note_names = list(set(note_names)) # simple de-dup for octave in range(-1, 9): for note in note_names: midi_number = pretty_midi.note_name_to_number(note + str(octave)) midi_numbers.append(midi_number) return sorted(midi_numbers) . We do not need to de-duplicate or sort for our current use, but I added those steps in case I supply some note names “out of order” ([D, C] instead of [C, D] for instance) or provide possible note duplicates for other uses. . Randomly Draw Notes . Here you can now use the collection of midi notes and just make a random choice from it at each step. For instance if g_maj_midi is the collection of MIDI notes for G Major then you can randomly select one with pitch = random.choice(g_maj_midi[21:36]) where we take a slice of the array to restrict the notes to just a couple of octaves. . Chord Accompaniment . We want to get just simple chords from the major scale for the piano to play them for whole notes. There are some existing Python packages that can be used: . chords2midi let’s you generate a MIDI file by supplying a progressing an a key: c2m I V vi IV --key C | chords2midi uses pychord, which will generate the component notes of a chord from its name as well as name a chord from its notes. | . These are both strong utilities that I will certainly use as I expand but for now I will do something much simpler. You can get a major scale chord progression by simply going to the scale and taking a note for the root and getting the third and fifth of a triad by just taking the second and fourth notes after your root. For instance, you can get a C (major) triad from the C major scale by looking at the scale CDEFGAB and using that pattern C_E_G__. Whether this is major or minor is irrelevant for our use: we just want to grab all the simple triads (not worrying about inversions or anything) and collect them together for one octave of root notes: . def get_major_progression(root_index, midi_numbers): chords = [] for i in range(8): chord_root_index = root_index + i chord_third_index = chord_root_index + 2 chord_fifth_index = chord_root_index + 4 root = midi_numbers[chord_root_index] third = midi_numbers[chord_third_index] fifth = midi_numbers[chord_fifth_index] chord = [root, third, fifth] chords.append(chord) return chords . This will generate a list of chord lists, where each chord list is the midi notes for a given triad. Note, if you do not feed the notes of a key as the MIDI numbers you will not get a major key progression, so this might be imperfectly named. . Vary the Rhythm . When we were adding notes one at a time we were keeping track of when the note began and when it ended in seconds. It would be nice to forget about when they begin and imagine writing the song and moving forward, adding notes “now.” To do this we make a writer for our instrument that keeps track of when “now” is and allows us to add notes one at a time, as a chord, or in a chunk of notes. Using this chunking allows us to vary the rhythm, we can randomly determine how long the next note(s) should be and then play a bunch of notes of that length. This is slightly more natural than varying each note independently, because shorter notes are often grouped together. . class Writer: def __init__(self, instrument): self.position = 0 self.instrument = instrument def add_note(self, pitch, length, move_forward=True): note = pretty_midi.Note(velocity=100, pitch=pitch, start=self.position, end=self.position + length) self.instrument.notes.append(note) if move_forward: self.position += length def add_note_series(self, pitches, length): for pitch in pitches: self.add_note(pitch, length) def add_chord(self, pitches, length, move_forward=True): for pitch in pitches: self.add_note(pitch, length, move_forward=False) if move_forward: self.position += length . We leave move_forward as an optional argument, because if we are writing notes that will occur at the same time (to form a chord) then we want the Writer “head” or position to stay at the same spot until we are done adding notes to that point in time. There are other simplifications that are made (no velocity changes), but this simple class gives us a lot of power so that we can more expressively generate midi music. . import pretty_midi from music_info import determine_key_notes import music_info import random # Create a PrettyMIDI object ensemble = pretty_midi.PrettyMIDI() # Create an Instrument instance for a cello instrument # Changed to a guitar for my song, and was lazy about changing variable names # cello_program = pretty_midi.instrument_name_to_program(&#39;Cello&#39;) cello_program = pretty_midi.instrument_name_to_program(&#39;Overdriven Guitar&#39;) cello = pretty_midi.Instrument(program=cello_program) # do the same for a piano piano_program = pretty_midi.instrument_name_to_program(&#39;Acoustic Grand Piano&#39;) piano = pretty_midi.Instrument(program=piano_program) # Add the instruments to the PrettyMIDI object ensemble.instruments.append(cello) ensemble.instruments.append(piano) # here is where I put the Writer class from above piano_writer = Writer(piano) cello_writer = Writer(cello) song_length_in_seconds = 30 bpm = 120 beat_length = 60 / bpm num_beats = int(song_length_in_seconds / beat_length) # Decided on G major, which is index 7 g_maj = music_info.determine_key_notes(7) g_maj_midi = music_info.get_all_midi_numbers(g_maj) root_number = pretty_midi.note_name_to_number(&quot;G4&quot;) root_index = g_maj_midi.index(root_number) major_progression = music_info.get_major_progression(root_index, g_maj_midi) accompaniment_writer = piano_writer solo_writer = cello_writer # now we see the power of the writer object while accompaniment_writer.position &lt; song_length_in_seconds: length = beat_length * 4 # whole note chords # choose a random chord from the progression chord = random.choice(major_progression) # add a lower octave of the notes for fullness larger_chord = chord + [n - 12 for n in chord] # write the chord accompaniment_writer.add_chord(larger_chord, length) while solo_writer.position &lt; song_length_in_seconds: # choose to play 16th, 8th, quarter, half, or whole note(s) division = random.choice([-2, -1, 0, 1, 2]) length = beat_length * (2 ** division) # if we chose 16th or 8th, play multiple of them if division &lt; 0: num_notes = 2 ** (-1 * division) pitches = random.choices(g_maj_midi[21:36], k=num_notes) solo_writer.add_note_series(pitches, length) else: pitch = random.choice(g_maj_midi[21:36]) solo_writer.add_note(pitch, length=beat_length) def write_song(): # Write out the MIDI data ensemble.write(&#39;duo.mid&#39;) . Now with this I created the following simple duet. It isn’t the most thrilling piece of music, but with relatively simple rules behind it, I think it is interesting how “complex” it sounds. .",
            "url": "http://simonstolarczyk.com/markdown/2020/08/02/Python_and_MIDI_2.html",
            "relUrl": "/markdown/2020/08/02/Python_and_MIDI_2.html",
            "date": " • Aug 2, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Making Music with pretty_midi",
            "content": "Making Music with pretty_midi . MIDI Music . A while back, when I was first learning Python, a friend and I made a program that generated random music by iterating through a song one note at a time randomly picking the note length and pitch for the notes with increasingly strict rules. My friend figured out how to use MIDIUtil to create a midi file by writing down a sequence of note events, where each event says something about: . velocity - how loud the note should be played | pitch - an integer value for telling a midi play what frequency to play | note start - when the note should start playing | note end - when it should stop | . You can do a lot of music with just that information, and if you make simple choices for notes, with the right MIDI player you can get surprisingly listenable music. I have wanted to expand on this program for a while in various ways: . generating music by applying machine learning techniques to various collections of midi files (like this Google Bach doodle) | making something more interactive (something involving the console where you can add motifs and ideas on the play and have them played back) | feed the program just a text file with a simplistic music notation to easily create ideas that can get more complex (like TidalCycles which uses Haskell and SuperCollider). | . Creating MIDI Files with Python . I searched around on pypi a bit and found a promising package to start writing MIDI files with: pretty_midi. It’s a project on GitHub that seems to still be active (part of why I am not just using MIDIUtil again is that I remember I slightly annoying setup and it seems to be inactive). After a simple install, and running the second example from the documentation I found that it easily generated pleasing sounds that (after a bit of fitzing) I could simply listen to with VLC Media Player. Before I just imported the files into Reaper where I could use a custom VST, but this makes iterating a bit quicker. . Here is an example I made where two instruments are playing a very minimalist piece: . import pretty_midi # Create a PrettyMIDI object ensemble = pretty_midi.PrettyMIDI() # Create an Instrument instance for a cello instrument cello_program = pretty_midi.instrument_name_to_program(&#39;Cello&#39;) cello = pretty_midi.Instrument(program=cello_program) # do the same for a piano piano_program = pretty_midi.instrument_name_to_program(&#39;Acoustic Grand Piano&#39;) piano = pretty_midi.Instrument(program=piano_program) # Add the instruments to the PrettyMIDI object ensemble.instruments.append(cello) ensemble.instruments.append(piano) song_length_in_seconds = 30 bpm = 120 beat_length = 60 / bpm num_beats = int(song_length_in_seconds / beat_length) for beat in range(num_beats): if beat % 2 == 0: note_name = &#39;C5&#39; else: note_name = &#39;D5&#39; note_number = pretty_midi.note_name_to_number(note_name) note_start = beat * beat_length note_end = note_start + beat_length note = pretty_midi.Note(velocity=100, pitch=note_number, start=note_start, end=note_end) cello.notes.append(note) piano.notes.append(note) def write_song(): # Write out the MIDI data ensemble.write(&#39;ensemble.mid&#39;) if __name__ == &quot;__main__&quot;: write_song() . This is a simple example, yet it shows the basics of the process that I will expand on: . add notes one at a time | incorporate some randomness into the note properties (here pitch changes deterministically, but that will soon change) | using multiple instruments | . I will begin to add to this, hopefully reaching what we achieved during my first experience with Python and MIDI and then think about ways to expand it and then start to apply some of my fastbook reading to it. .",
            "url": "http://simonstolarczyk.com/markdown/2020/08/01/Python_and_MIDI.html",
            "relUrl": "/markdown/2020/08/01/Python_and_MIDI.html",
            "date": " • Aug 1, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "DataPlox",
            "content": "DataPlox . In understanding how to properly feed young, growing models, it is useful to know some of the main data objects in PyTorch and fastai. Fastai extends many of the fundamental PyTorch objects. Here’s the picture that I have in my head: . . For the main PyTorch data classes: . Dataset | DataLoader | . The fastai library extends them with: . Datasets | DataLoaders | . and adds a useful class which can help construct the others: . DataBlock | . DataBlock . This is a fastai object which helps you build Datasets and DataLoaders. In addition to Chapter 6 of the fastbook, there is also a tutorial in the fastai docs. A DataBlock is a blueprint for how to build your data. You tell it: . what kind of data you have (blocks=), | how to get the input data (get_x= or get_items=), | how to get the targets/labels (get_y), | how to perform the train/validation split (splitter=), | as well as any resizing (items_tfms=) or augmentations you want to be performed (batch_tfms). | . By feeding these blue prints a source (like a directory on your computer), you can use a DataBlock to create a Datasets or DataLoaders object. . Dataset . Dataset is a Torch object. We can find out exactly what a Dataset is because PyTorch is open source. We just have to be brave enough to parse some of the grittier implementation details. . According to the source code a Dataset is at its core something that allows you to grab an item if you provide the index/key for it and that you can also add items to. This is just the abstract class definition, essentially the bare bones of a what a dataset should be. If you try to make a class that inherits from Dataset you will get an error if you do not implement __getitem__, the method for grabbing items. It does this by setting the default behavior of that method to raise a NotImplementedError. You can also implement this behavior (forcing inheriting classes to define specific methods) by using the abc package. The source code also mentions that it would have set a default for a length function, but the standard methods for making a default that is forced to change have conflicts with what a length function is “supposed” to do. . The types of Datasets are: . IterableDataset | TensorDataset | ConcatDataset | ChainDataset | Subset | . Datasets . Datasets is an object that contains a training Dataset and a validation Dataset. You can generally construct a Datasets object from a DataBlock like this: . dblock = DataBlock(blue_print_details) dsets = dblock.datasets(source) . DataLoader . A DataLoader is a Dataset together with a Sampler. A Sampler is a way to create an iterator out of your Dataset, so you can do things like consume data in batches as needed. Rather than take a Dataset an manually loop through chunks of it, at each step using a chunk to update a model, a DataLoader bundles this idea together. This makes a lot of sense to encapsulate: going through your data in batches is a frequently encountered process in machine learning! . We can see from the source code that a Sampler is at minimum: . a way to iterate over indices of dataset elements (__iter__) and | a way to calculate the size of the returned iterators (__len__). | . Just like with DataSet, defining the length method is not strictly enforced by the interpreter because the various NotImplemented errors you can throw do not quite work.` . The kinds of samplers: . SequentialSampler - go in direct 0, 1, 2, … order. | RandomSampler - randomly choose observations, with or without replacement (replacement=) | SubsetRandomSampler - randomly sample from a provided subset of indices, without replacement | WeightedRandomSampler - for non-uniform random sampling | BatchSampler - generate mini-batches of indices | . For DataLoader, the definition is a bit more involved. In part, because it implements multiprocessing, but it also does things like creating a Sampler from the arguments if one wasn’t provided. . DataLoaders . DataLoaders is an object that contains a training DataLoader and a validation DataLoader. You can construct a DataLoaders from a DataBlock similarly to the Datasets method: . dblock = DataBlock(blue_print_details) dls = dblock.dataloaders(source) .",
            "url": "http://simonstolarczyk.com/markdown/2020/07/23/data_objects.html",
            "relUrl": "/markdown/2020/07/23/data_objects.html",
            "date": " • Jul 23, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "FastBook Chapter 5 Thoughts",
            "content": "FastBook Chapter 5 Thoughts . After reading the first half of chapter 3 (will read the second half this week) and (mostly) breezing through Chapter 4 (it contained a lot of familiar material), I worked on Chapter 5 this weekend. . Import concepts: . Presizing. | Checking your DataBlock before you begin training | Train early (get a reasonable MVP) and often (if it’s not too expensive). | Cross-Entropy Loss for the binary case and extending it to multi-class examples. | Confusion matrix with ClassificationInterpretation and looking at the most_confused examples. | Learning Rate Finder | More particulars on transfer learning, including how to use discriminative learning rates to not lose the solid training of the transferred modeled. | . Some Notes During Reading . Presizing is a particular way to do image augmentation that is designed to minimize data destruction while maintaining good performance. The general idea is to apply a composition of the augmentation operations all at once rather than iteratively augment and interpolate. This has savings both in terms of computation and the final quality of the examples. . In the 3s and 7s table there is a column labeled “loss”, which for me was a bit confusing. In the first row loss was the predicted output of the “3” class, which happened to be the correct answer. However, loss was just the output of that example, which does not quite make sense because you are looking to minimize loss which conflicts with the goal of maximizing the predicted output for the true class. It looks like this was just an oversight with the naming convention because to compute the loss more things are done and the text that follows makes this clear. . I found it useful to explicitly calculate the loss in the binary example provided. . Activations: . acts[0, :] . tensor([0.6734, 0.2576]) . class0_act = acts[0, 0] class1_act = acts[0, 1] class0_act . tensor(0.6734) . Computing the exponential of the activations to then get the softmax. . from math import exp exp0 = exp(class0_act) exp0 . 1.9608552547588787 . exp1 = exp(class1_act) smax0 = exp0 / (exp0 + exp1) smax0 . 0.602468670578454 . smax1 = exp1 / (exp0 + exp1) smax1 . 0.39753132942154595 . smax0 + smax1 . 1.0 . from math import log log(smax0) . -0.5067196140092344 . log(smax1) . -0.9224815318387478 . -log(smax0) . 0.5067196140092344 . And that is the loss for the first example, because the true class was 0. This matches the calculation using the fastai classes, which is always a relief. . References to Read . Cyclical Learning Rates for Training Neural Networks | How transferable are features in deep neural networks? | . Thoughts on selected Qs . Why do we first resize to a large size on the CPU, and then to a smaller size on the GPU? . You want to create a uniform input size for your data and also apply various transformations to augment it. The presizing method, running augmentation transformations as a single composition rather than iteratively, allows you to have larger/more “rich” inputs to transform before making them a smaller, uniform size that you will train the model with. . | What are the two ways in which data is most commonly provided, for most deep learning datasets? . A collection of data elements, that have filenames indicating information about them, like their class. (A folder of pictures where each picture has a file name with its ID and class). | Tabular format that can either contain the data in each row (along with the metadata) or point to data in other formats. (A csv file with ID, true class, and a hyper link to the input picture.) | | Look up the documentation for L and try using a few of the new methods is that it adds. . L is a beefier list class. How it’s different from a regular list: . the print function is smarter. It provides the length of the list and truncates the end, which is nice if you’ve ever crashed a server because you accidentally printed out an obscenely long list. | you can access L with a tuple, whereas a normal list will break if you try to access it that way. | it has unique(), which functions like the same method in Pandas. | it has a filter method attribute. | . | Look up the documentation for the Python pathlib module and try using a few methods of the Path class. . Path was introduced to Python in 3.4. It appears to combine a bunch of common things that you typically use os with along with the ability to manage file paths without doing string manipulations (as well as reducing the vs / mistakes that are frequently made). . One nice thing that can be done, set here = Path(&#39;.&#39;) and then iterate over the current directory with for f in here.iterdir(): print(f). You can also .open() a path object rather than feeding it to open() and do glob stuff. . | Give two examples of ways that image transformations can degrade the quality of the data. . Image simply rotating a square 45 degrees to stand it up on one corner. Now the new image that you get (take an old square position cut out of the rotated square position) is missing anything in the corners, so it has to be interpolated. This loses about 17% of the original image, so it’s pretty significant! | Brightening an image will move the brighter pixels up to the maximum brightness, so their original brightness cannot be recovered by simply redarkening. | | What method does fastai provide to view the data in a DataLoaders? . You can use .show_batch(nrows, ncols) on the DataLoaders object to get a grid of some of the examples. . | What method does fastai provide to help you debug a DataBlock? . Using .summary() on the DataBlock object gives a verbose attempt to try and create the batch. The output from this, along with errors that come up if it fails can help you notice a problem. . | Should you hold off on training a model until you have thoroughly cleaned your data? . No, sometimes life is easy! Also, it’s good to get reasonable bench marks as soon as possible. Not only to help game-ify the problem and motivate you to work on it, but also to have a baseline to see if the room for improvement is worth the energy. . | What are the two pieces that are combined into cross-entropy loss in PyTorch? . nn.CrossEntropyLoss (see the docs) applies nll_loss after log_softmax (which is log of softmax) . | What are the two properties of activations that softmax ensures? Why is this important? . You can interpret activations as probabilities. outputs sum to one | outputs are non-negative | . | It forces the model to favor a single class. | This more relevant behavior that is mentioned that it amplifies small differences, which is useful if you want the network to be somewhat decisive rather than having all outputs close to each other. . | When might you want your activations to not have these two properties? . The parenthetical comment in the main text mentions that you may not want the model to pick a class just because it has a slightly larger output. You want the model to be sure about the class, not just relatively sure. . For the probability property, it might be misleading because it isn’t necessarily the actual probability of the example being that class. . | Why can’t we use torch.where to create a loss function for datasets where our label can have more than two categories? . In part, this is a constraint of the where function. Where selects between two outputs based on a condition. It is too difficult to right a nested condition when you have more than two outcomes and selecting the loss requires a bit more work, so this trick becomes way less convenient. . | What are two good rules of thumb for picking a learning rate from the learning rate finder? . One order of magnitude less than where the minimum loss was achieved (i.e., the minimum divided by 10). | The last point where the loss was clearly decreasing | . | What two steps does the fine_tune method do? . We go to the source: . self.freeze() self.fit_one_cycle(freeze_epochs, slice(base_lr), pct_start=0.99, **kwargs) base_lr /= 2 self.unfreeze() self.fit_one_cycle(epochs, slice(base_lr/lr_mult, base_lr), pct_start=pct_start, div=div, **kwargs) . Thus it: 1. Performs a one-cycle fit with the pre-trained layers frozen (their weights do not update). 2. Performs another one-cycle fit with the pre-trained layers unfrozen at half the learning rate. . | What are discriminative learning rates? . The idea here is that you may want weights in certain layers to change at a different rate. In particular, if your first layers come from a pretrained network you may want to do updates to them more slowly than the last layers which are tailored to your particular problem. . | How is a Python slice object interpreted when passed as a learning rate to fastai? . It acts like numpy.linspace where the num is implicitly defined as the number of layers. . | Why is early stopping a poor choice when using 1cycle training? . For a description of 1cycle training, the fastai docs refer to the rate finder paper in the references as well as this blog post. It looks like the basic idea is stopping early does give the training a chance to be finely tuned, because you are likely stopping at a point where the learning rate is still large. . | What is the difference between resnet50 and resnet101? . Both resnet50 and resnet100 are residual networks, and seem to have been introduced in Deep Residual Learning for Image Recognition. The basic idea of deep residual networks seems to be “wire a network that is trying to learn the function $ mathcal{H}(x)$ such that it has to learn $ mathcal{H}(x) - x$ instead.” The intuition being that, for example, it is easier to learn the zero function than it is to learn the identity function. resnet-50 looks like it was obtain from the resnet-34 architecture by replacing certain layer pairs with layer triplets known as bottleneck blocks. resnet-101 (and resnet-152) are just an expansion of this idea, adding 17 more (or 34 more) of these triplet-layer blocks. . | What does to_fp16 do? . The other downside of deeper architectures is that they take quite a bit longer to train. One technique that can speed things up a lot is mixed-precision training. This refers to using less-precise numbers (half-precision floating point, also called fp16) where possible during training. As we are writing these words in early 2020, nearly all current NVIDIA GPUs support a special feature called tensor cores that can dramatically speed up neural network training, by 2-3x. They also require a lot less GPU memory. To enable this feature in fastai, just add to_fp16() after your Learner creation (you also need to import the module). . |",
            "url": "http://simonstolarczyk.com/markdown/2020/07/21/fastbook_ch5.html",
            "relUrl": "/markdown/2020/07/21/fastbook_ch5.html",
            "date": " • Jul 21, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Solving a Nightmare with a Headache",
            "content": "Solving a Nightmare with a Headache . Issue: The widgets in Jupyter Notebook were not all displaying. . Non-solution: Try re-do some installs in the virtualenv. While I am at it, let’s also try out pyenv. . New Issue: Windows does not play well with pyenv. You can get pyenv to work, but then virtualenv is no longer set up on your global environment. . Attempted Solution: Try to clone the pyenv-virtualenv repo into a new plugins directory of the pyenv root folder. This did not work, despite sinking about an hour into this whole mess. . New Issue: It’s time to put Linux on my machine to try and escape some of these Windows nightmares. This is going to be a headache, but it seems like the pay off will be worth-while, given that the Fastbook also doesn’t play well with Windows. I have been frustrated with doing Python things on Windows before so I had Linux available already. I will note that it took be a while to remember I already had a Linux partition and in a cascading wave of failure, I forgot my linux password, so was not able to run a needed sudo command. But, I got lucky again (and this is a yikes security-wise) and it turns out you can easily reset the password for Ubuntu. . From here I followed Real Python’s primer on pyenv. Setting this up was not bad and putting some lines in .bashrc virtualenv becomes much nicer to use. It allows you connect a particular environment to a folder. I created a virtualenv named fab (FastAI Book, short environment names are good when you’re used to activating an environment every time you want to work on something) by again following Real Python and now it is automatically activated when I am in the fastbook directory. A quick pip install -r requirements.txt -v got the environment running smoothly with the notebook for Chapter 1, and things that did not work 100% in Windows worked in my Linux boot nicely (at least after a sudo apt install graphviz): . I could run the cells without having to change num_workers to 0. | My GPU was visible to Torch (torch.cuda.get_device_name(0) returned the name of my GPU). | The text example, which did not work at all on Windows, ran. | And, the whole reason I started this endeavor: when I created the FileUploader widget, it appeared in the notebook. | .",
            "url": "http://simonstolarczyk.com/markdown/2020/07/12/wind_nightmare.html",
            "relUrl": "/markdown/2020/07/12/wind_nightmare.html",
            "date": " • Jul 12, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "FastAI Book Chapter 2",
            "content": "FastAI Book Chapter 2 . I went through the second chapter of the book today, which is why this blog even exists. Highly useful; looking forward to working on some music projects to really learn the material. . Things I Learned . How to easily build an image classifier to discern between blue jays, mockingbirds, and shrikes. | . I chose the first two bird types based on my familiarity and their Cool Local Bird ranks. I was going to select a cardinal as a third class, but thought it would be too easy to detect the class based solely on color, so I searched around and found shrikes, which looked similar to mockingbirds. The classifier performed very well, which was I semi-shock because I didn’t know: . You do not always need a lot of data to build a decent model. | . Even with 150 examples of each of three classes (before train/validation split), there were only 3 misclassifications on the validation set. This shows how powerful data augmentation can be, but also helps dispel the notion that you need tons of data to do anything reasonable. . FastAI has some powerful tools that I need to learn. | . Easily display the examples with the highest loss and lowest confidence to see if I can interpret possible deficiencies with interp.plot_top_losses(). | Clean up the dataset with ImageClassifierCleaner, manually going through some of the examples to change labels or remove them, and then effect the changes with a couple simple for-loops. | Use verify_images to clean up corrupted files easily. | Use DataBlock to define the structure of the problem and implement useful transformations for the data. | Think about how to normalize images. | . Squashing a large image into a smaller one with simple scaling or adding cropped parts of small images is maybe not the best way to make sure the inputs are all “from the same distribution”. You can use RandomResizedCrop to maintain original image quality and also artificially expand the size of your training set. . Other things: How to easily build a dataset with the Bing Image API. | The usefulness of Path (which I only recently learned about) was really demonstrated nicely. | The Drivetrain Approach. | Creating a Notebook App with widgets and Voilà. (Admittedly, I’m still trying to get the latter to work.) | . | . Things I Had to Troubleshoot . How do you find the Bing Image Search key? | . Solution: I signed up for the free Azure thing, went to to the Bing Image Search API, and just had to click to add Bing Search APIs v7 to my subscription. Once I did this it brought up a page with the keys and endpoints. . I am using my local computer, with Windows, to run the notebooks. So, I have run into (standard) issues. Namely, I saw RuntimeError: cuda runtime error (801) : operation not supported at... when I first attempted to fine tune the learner learn.fine_tune(4). | . Solution: When you google the error this issue page points you to the forum, but also usefully mentions the “need to set num_workers=0 when creating a DataLoaders because Pytorch multiprocessing does not work on Windows.” So, doing this when you define the dataloaders dls = bears.dataloaders(path, num_workers=0) cleared it up for me. . Some minor formatting issues with interp.plot_top_losses(5, nrows=1). The text above the images was overlapping, because my class names were a bit long. | . Simple fix was to set nrows=5. .",
            "url": "http://simonstolarczyk.com/markdown/2020/07/11/fastai_book_ch2.html",
            "relUrl": "/markdown/2020/07/11/fastai_book_ch2.html",
            "date": " • Jul 11, 2020"
        }
        
    
  
    
  
    
        ,"post8": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "http://simonstolarczyk.com/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "http://simonstolarczyk.com/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "http://simonstolarczyk.com/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}